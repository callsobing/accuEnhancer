{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "This tutorial shows a complete model process of one cell type from:\n",
    "* Data preparation\n",
    "* Data preprocess\n",
    "* Model training, test performance evaluation\n",
    "* Independent test prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Input\n",
    "* Reference genome\n",
    "* Cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select your reference genome\n",
    "ref_genome = 'hg19' # or 'hg38'\n",
    "\n",
    "# Select your cell type (here Roadmap id)\n",
    "cell_type = 'E034'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prepare data\n",
    "* Get reference genome\n",
    "* This example shows the path of hg19 build from UCSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-15 11:13:09--  https://hgdownload.soe.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz\n",
      "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
      "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 948731419 (905M) [application/x-gzip]\n",
      "Saving to: ‘hg19.fa.gz’\n",
      "\n",
      "hg19.fa.gz            0%[                    ]   2.34M   889KB/s               ^C\n",
      "\n",
      "gzip: data/reference_genome/hg19.fa.gz: unexpected end of file\n"
     ]
    }
   ],
   "source": [
    "# get reference genome\n",
    "! mkdir -p data/reference_genome/\n",
    "! wget https://hgdownload.soe.ucsc.edu/goldenPath/{ref_genome}/bigZips/{ref_genome}.fa.gz\n",
    "! mv {ref_genome}.fa.gz data/reference_genome/\n",
    "! gunzip data/reference_genome/{ref_genome}.fa.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "* Generate 200-bp bed and fasta file from reference genome\n",
    "* Output: `data/200bp_bin.bed`. `data/200bp_bin.fa` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Feature (chr1:249250600-249250800) beyond the length of chr1 size (249250621 bp).  Skipping.\r\n",
      "Feature (chr2:243199200-243199400) beyond the length of chr2 size (243199373 bp).  Skipping.\r\n",
      "Feature (chr3:198022400-198022600) beyond the length of chr3 size (198022430 bp).  Skipping.\r\n",
      "Feature (chr4:191154200-191154400) beyond the length of chr4 size (191154276 bp).  Skipping.\r\n",
      "Feature (chr5:180915200-180915400) beyond the length of chr5 size (180915260 bp).  Skipping.\r\n",
      "Feature (chr6:171115000-171115200) beyond the length of chr6 size (171115067 bp).  Skipping.\r\n",
      "Feature (chr7:159138600-159138800) beyond the length of chr7 size (159138663 bp).  Skipping.\r\n",
      "Feature (chr8:146364000-146364200) beyond the length of chr8 size (146364022 bp).  Skipping.\r\n",
      "Feature (chr9:141213400-141213600) beyond the length of chr9 size (141213431 bp).  Skipping.\r\n",
      "Feature (chr10:135534600-135534800) beyond the length of chr10 size (135534747 bp).  Skipping.\r\n",
      "Feature (chr11:135006400-135006600) beyond the length of chr11 size (135006516 bp).  Skipping.\r\n",
      "Feature (chr12:133851800-133852000) beyond the length of chr12 size (133851895 bp).  Skipping.\r\n",
      "Feature (chr13:115169800-115170000) beyond the length of chr13 size (115169878 bp).  Skipping.\r\n",
      "Feature (chr14:107349400-107349600) beyond the length of chr14 size (107349540 bp).  Skipping.\r\n",
      "Feature (chr15:102531200-102531400) beyond the length of chr15 size (102531392 bp).  Skipping.\r\n",
      "Feature (chr16:90354600-90354800) beyond the length of chr16 size (90354753 bp).  Skipping.\r\n",
      "Feature (chr17:81195200-81195400) beyond the length of chr17 size (81195210 bp).  Skipping.\r\n",
      "Feature (chr18:78077200-78077400) beyond the length of chr18 size (78077248 bp).  Skipping.\r\n",
      "Feature (chr19:59128800-59129000) beyond the length of chr19 size (59128983 bp).  Skipping.\r\n",
      "Feature (chr20:63025400-63025600) beyond the length of chr20 size (63025520 bp).  Skipping.\r\n",
      "Feature (chr21:48129800-48130000) beyond the length of chr21 size (48129895 bp).  Skipping.\r\n",
      "Feature (chr22:51304400-51304600) beyond the length of chr22 size (51304566 bp).  Skipping.\r\n",
      "Feature (chrX:155270400-155270600) beyond the length of chrX size (155270560 bp).  Skipping.\r\n",
      "Feature (chrY:59373400-59373600) beyond the length of chrY size (59373566 bp).  Skipping.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! python preprocess/get_sequences.py --genome data/genome/{ref_genome}.fa --out data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get H3K27ac and DNase narrowPeak files of a specific cell type\n",
    "* This example shows the Roadmap path of BLD.CD3.PPC data (E034)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-10-15 11:13:37--  https://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/E034-H3K27ac.narrowPeak.gz\n",
      "Resolving egg2.wustl.edu (egg2.wustl.edu)... 128.252.187.85\n",
      "Connecting to egg2.wustl.edu (egg2.wustl.edu)|128.252.187.85|:443... connected.\n",
      "^C\n",
      "--2020-10-15 11:13:38--  https://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/E034-DNase.macs2.narrowPeak.gz\n",
      "Resolving egg2.wustl.edu (egg2.wustl.edu)... 128.252.187.85\n",
      "Connecting to egg2.wustl.edu (egg2.wustl.edu)|128.252.187.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5671786 (5.4M) [application/x-gzip]\n",
      "Saving to: ‘E034-DNase.macs2.narrowPeak.gz’\n",
      "\n",
      "034-DNase.macs2.nar   8%[>                   ] 481.99K   216KB/s               ^C\n"
     ]
    }
   ],
   "source": [
    "# get peaks files\n",
    "! mkdir -p data/peakfiles\n",
    "! wget https://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/{cell_type}-H3K27ac.narrowPeak.gz\n",
    "! wget https://egg2.wustl.edu/roadmap/data/byFileType/peaks/consolidated/narrowPeak/{cell_type}-DNase.macs2.narrowPeak.gz\n",
    "! mv {cell_type}* data/peakfiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocess\n",
    "* Generate positive and negative samples (1:10 in train, 1:5 in test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Now fetching signal values from h3k27ac bed files...\n",
      "### Now fetching signal values from dnase bed files...\n",
      "### Now selecting negative seq from hg38 200bp bins pool...\n",
      "Processed 0 negative sequences...\n",
      "Processed 324856 negative sequences...\n",
      "Processed 649712 negative sequences...\n",
      "Processed 974568 negative sequences...\n",
      "Processed 1299424 negative sequences...\n",
      "Processed 1624280 negative sequences...\n",
      "Processed 1949136 negative sequences...\n",
      "Processed 2273992 negative sequences...\n",
      "Processed 2598848 negative sequences...\n",
      "Processed 2923704 negative sequences...\n",
      "### Now processing positive bins...\n",
      "Processed 50000 positive sequences for selected dnase...\n",
      "Processed 100000 positive sequences for selected dnase...\n",
      "Processed 150000 positive sequences for selected dnase...\n",
      "Processed 200000 positive sequences for selected dnase...\n",
      "Processed 250000 positive sequences for selected dnase...\n",
      "Processed 300000 positive sequences for selected dnase...\n",
      "### Now processing negative bins...\n",
      "Processed 50000 positive sequences for selected dnase...\n",
      "Processed 100000 positive sequences for selected dnase...\n",
      "Processed 150000 positive sequences for selected dnase...\n",
      "Processed 200000 positive sequences for selected dnase...\n",
      "Processed 250000 positive sequences for selected dnase...\n",
      "Processed 300000 positive sequences for selected dnase...\n",
      "Processed 350000 positive sequences for selected dnase...\n",
      "Processed 400000 positive sequences for selected dnase...\n",
      "Processed 450000 positive sequences for selected dnase...\n",
      "Processed 500000 positive sequences for selected dnase...\n",
      "Processed 550000 positive sequences for selected dnase...\n",
      "Processed 600000 positive sequences for selected dnase...\n",
      "Processed 650000 positive sequences for selected dnase...\n",
      "Processed 700000 positive sequences for selected dnase...\n",
      "Processed 750000 positive sequences for selected dnase...\n",
      "Processed 800000 positive sequences for selected dnase...\n",
      "Processed 850000 positive sequences for selected dnase...\n",
      "Processed 900000 positive sequences for selected dnase...\n",
      "Processed 950000 positive sequences for selected dnase...\n",
      "Processed 1000000 positive sequences for selected dnase...\n",
      "Processed 1050000 positive sequences for selected dnase...\n",
      "Processed 1100000 positive sequences for selected dnase...\n",
      "Processed 1150000 positive sequences for selected dnase...\n",
      "Processed 1200000 positive sequences for selected dnase...\n",
      "Processed 1250000 positive sequences for selected dnase...\n",
      "Processed 1300000 positive sequences for selected dnase...\n",
      "Processed 1350000 positive sequences for selected dnase...\n",
      "Processed 1400000 positive sequences for selected dnase...\n",
      "Processed 1450000 positive sequences for selected dnase...\n",
      "Processed 1500000 positive sequences for selected dnase...\n",
      "Processed 1550000 positive sequences for selected dnase...\n",
      "Processed 1600000 positive sequences for selected dnase...\n",
      "Processed 1650000 positive sequences for selected dnase...\n",
      "Processed 1700000 positive sequences for selected dnase...\n",
      "Processed 1750000 positive sequences for selected dnase...\n",
      "Processed 1800000 positive sequences for selected dnase...\n",
      "Processed 1850000 positive sequences for selected dnase...\n",
      "Processed 1900000 positive sequences for selected dnase...\n",
      "Processed 1950000 positive sequences for selected dnase...\n",
      "Processed 2000000 positive sequences for selected dnase...\n",
      "Processed 2050000 positive sequences for selected dnase...\n",
      "Processed 2100000 positive sequences for selected dnase...\n",
      "Processed 2150000 positive sequences for selected dnase...\n",
      "Processed 2200000 positive sequences for selected dnase...\n",
      "Processed 2250000 positive sequences for selected dnase...\n",
      "Processed 2300000 positive sequences for selected dnase...\n",
      "Processed 2350000 positive sequences for selected dnase...\n",
      "Processed 2400000 positive sequences for selected dnase...\n",
      "Processed 2450000 positive sequences for selected dnase...\n",
      "Processed 2500000 positive sequences for selected dnase...\n",
      "Processed 2550000 positive sequences for selected dnase...\n",
      "Processed 2600000 positive sequences for selected dnase...\n",
      "Processed 2650000 positive sequences for selected dnase...\n",
      "Processed 2700000 positive sequences for selected dnase...\n",
      "Processed 2750000 positive sequences for selected dnase...\n",
      "Processed 2800000 positive sequences for selected dnase...\n",
      "Processed 2850000 positive sequences for selected dnase...\n",
      "Processed 2900000 positive sequences for selected dnase...\n",
      "Processed 2950000 positive sequences for selected dnase...\n",
      "Processed 3000000 positive sequences for selected dnase...\n",
      "Processed 3050000 positive sequences for selected dnase...\n",
      "Processed 3100000 positive sequences for selected dnase...\n",
      "Processed 3150000 positive sequences for selected dnase...\n",
      "Processed 3200000 positive sequences for selected dnase...\n"
     ]
    }
   ],
   "source": [
    "! python preprocess/process_narrowpeaks.py \\\n",
    "        --h3k27ac_file data/peakfiles/{cell_type}-H3K27ac.narrowPeak.gz \\\n",
    "        --epi_file data/peakfiles/{cell_type}-DNase.macs2.narrowPeak.gz \\\n",
    "        --hg38_fasta_bins data/200bp_bin.fa \\\n",
    "        --hg38_bed_bins data/200bp_bin.bed \\\n",
    "        --output_name {cell_type}_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "* Pack to .h5 file as model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# === Creating a Training, Test and Validation Set from provided input === #\n",
      "\n",
      "Reading lines ...\n",
      "\n",
      "Converting to binary representation:\n",
      "\n",
      "###-- Epigenetic Feature Length = 25 --###\n",
      "\n",
      "Converting to binary representation:\n",
      "\n",
      "Sampled into sets ...\n",
      "\n",
      "Storing Coordinates ...\n",
      "\n",
      "Initializing hdf5 Storage Files ...\n",
      "\n",
      "Running through raw file again, converting sequences and store in sets ...\n",
      "Converting and storing sequences of length 200 bp.\n",
      "Written lines ... 0\n",
      "Written lines ... 10000\n",
      "Written lines ... 20000\n",
      "Written lines ... 30000\n",
      "Written lines ... 40000\n",
      "Written lines ... 50000\n",
      "Written lines ... 60000\n",
      "Written lines ... 70000\n",
      "Written lines ... 80000\n",
      "Written lines ... 90000\n",
      "Written lines ... 100000\n",
      "Written lines ... 110000\n",
      "Written lines ... 120000\n",
      "Written lines ... 130000\n",
      "Written lines ... 140000\n",
      "Written lines ... 150000\n",
      "Written lines ... 160000\n",
      "Written lines ... 170000\n",
      "Written lines ... 180000\n",
      "Written lines ... 190000\n",
      "Written lines ... 200000\n",
      "Written lines ... 210000\n",
      "Written lines ... 220000\n",
      "Written lines ... 230000\n",
      "Written lines ... 240000\n",
      "Written lines ... 250000\n",
      "Written lines ... 260000\n",
      "Written lines ... 270000\n",
      "Written lines ... 280000\n",
      "Written lines ... 290000\n",
      "Written lines ... 300000\n",
      "Written lines ... 310000\n",
      "Written lines ... 320000\n",
      "Written lines ... 330000\n",
      "Written lines ... 340000\n",
      "Written lines ... 350000\n",
      "Written lines ... 360000\n",
      "Written lines ... 370000\n",
      "Written lines ... 380000\n",
      "Written lines ... 390000\n",
      "Written lines ... 400000\n",
      "Written lines ... 410000\n",
      "Written lines ... 420000\n",
      "Written lines ... 430000\n",
      "Written lines ... 440000\n",
      "Written lines ... 450000\n",
      "Written lines ... 460000\n",
      "Written lines ... 470000\n",
      "Written lines ... 480000\n",
      "Written lines ... 490000\n",
      "Written lines ... 500000\n",
      "Written lines ... 510000\n",
      "Written lines ... 520000\n",
      "Written lines ... 530000\n",
      "Written lines ... 540000\n",
      "Written lines ... 550000\n",
      "Written lines ... 560000\n",
      "Written lines ... 570000\n",
      "Written lines ... 580000\n",
      "Written lines ... 590000\n",
      "Written lines ... 600000\n",
      "Written lines ... 610000\n",
      "Written lines ... 620000\n",
      "Written lines ... 630000\n",
      "Written lines ... 640000\n",
      "Written lines ... 650000\n",
      "Written lines ... 660000\n",
      "Written lines ... 670000\n",
      "Written lines ... 680000\n",
      "Written lines ... 690000\n",
      "Written lines ... 700000\n",
      "Written lines ... 710000\n",
      "Written lines ... 720000\n",
      "Written lines ... 730000\n",
      "Written lines ... 740000\n",
      "Written lines ... 750000\n",
      "Written lines ... 760000\n",
      "Written lines ... 770000\n",
      "Written lines ... 780000\n",
      "Written lines ... 790000\n",
      "Written lines ... 800000\n",
      "Written lines ... 810000\n",
      "Written lines ... 820000\n",
      "Written lines ... 830000\n",
      "Written lines ... 840000\n",
      "Written lines ... 850000\n",
      "Written lines ... 860000\n",
      "Written lines ... 870000\n",
      "Written lines ... 880000\n",
      "Written lines ... 890000\n",
      "Written lines ... 900000\n",
      "Written lines ... 910000\n",
      "Written lines ... 920000\n",
      "Written lines ... 930000\n",
      "Written lines ... 940000\n",
      "Written lines ... 950000\n",
      "Written lines ... 960000\n",
      "Written lines ... 970000\n",
      "Written lines ... 980000\n",
      "Written lines ... 990000\n",
      "Written lines ... 1000000\n",
      "Written lines ... 1010000\n",
      "Written lines ... 1020000\n",
      "Written lines ... 1030000\n",
      "Written lines ... 1040000\n",
      "Written lines ... 1050000\n",
      "Written lines ... 1060000\n",
      "Written lines ... 1070000\n",
      "Written lines ... 1080000\n",
      "Written lines ... 1090000\n",
      "Written lines ... 1100000\n",
      "Written lines ... 1110000\n",
      "Written lines ... 1120000\n",
      "Written lines ... 1130000\n",
      "Written lines ... 1140000\n",
      "Written lines ... 1150000\n",
      "Written lines ... 1160000\n",
      "Written lines ... 1170000\n",
      "Written lines ... 1180000\n",
      "Written lines ... 1190000\n",
      "Written lines ... 1200000\n",
      "Written lines ... 1210000\n",
      "Written lines ... 1220000\n",
      "Written lines ... 1230000\n",
      "Written lines ... 1240000\n",
      "Written lines ... 1250000\n",
      "Written lines ... 1260000\n",
      "Written lines ... 1270000\n",
      "Written lines ... 1280000\n",
      "Written lines ... 1290000\n",
      "Written lines ... 1300000\n",
      "Written lines ... 1310000\n",
      "Written lines ... 1320000\n",
      "Written lines ... 1330000\n",
      "Written lines ... 1340000\n",
      "Written lines ... 1350000\n",
      "Written lines ... 1360000\n",
      "Written lines ... 1370000\n",
      "Written lines ... 1380000\n",
      "Written lines ... 1390000\n",
      "Written lines ... 1400000\n",
      "Written lines ... 1410000\n",
      "Written lines ... 1420000\n",
      "Written lines ... 1430000\n",
      "Written lines ... 1440000\n",
      "Written lines ... 1450000\n",
      "Written lines ... 1460000\n",
      "Written lines ... 1470000\n",
      "Written lines ... 1480000\n",
      "Written lines ... 1490000\n",
      "Written lines ... 1500000\n",
      "Written lines ... 1510000\n",
      "Written lines ... 1520000\n",
      "Written lines ... 1530000\n",
      "Written lines ... 1540000\n",
      "Written lines ... 1550000\n",
      "Written lines ... 1560000\n",
      "Written lines ... 1570000\n",
      "Written lines ... 1580000\n",
      "Written lines ... 1590000\n",
      "Written lines ... 1600000\n",
      "Written lines ... 1610000\n",
      "Written lines ... 1620000\n",
      "Written lines ... 1630000\n",
      "Written lines ... 1640000\n",
      "Written lines ... 1650000\n",
      "Written lines ... 1660000\n",
      "Written lines ... 1670000\n",
      "Written lines ... 1680000\n",
      "Written lines ... 1690000\n",
      "Written lines ... 1700000\n",
      "Written lines ... 1710000\n",
      "Written lines ... 1720000\n",
      "Written lines ... 1730000\n",
      "Written lines ... 1740000\n",
      "Written lines ... 1750000\n",
      "Written lines ... 1760000\n",
      "Written lines ... 1770000\n",
      "Written lines ... 1780000\n",
      "Written lines ... 1790000\n",
      "Written lines ... 1800000\n",
      "Written lines ... 1810000\n",
      "Written lines ... 1820000\n",
      "Written lines ... 1830000\n",
      "Written lines ... 1840000\n",
      "Written lines ... 1850000\n",
      "Written lines ... 1860000\n",
      "Written lines ... 1870000\n",
      "Written lines ... 1880000\n",
      "Written lines ... 1890000\n",
      "Written lines ... 1900000\n",
      "Written lines ... 1910000\n",
      "Written lines ... 1920000\n",
      "Written lines ... 1930000\n",
      "Written lines ... 1940000\n",
      "Written lines ... 1950000\n",
      "Written lines ... 1960000\n",
      "Written lines ... 1970000\n",
      "Written lines ... 1980000\n",
      "Written lines ... 1990000\n",
      "Written lines ... 2000000\n",
      "Written lines ... 2010000\n",
      "Written lines ... 2020000\n",
      "Written lines ... 2030000\n",
      "Written lines ... 2040000\n",
      "Written lines ... 2050000\n",
      "Written lines ... 2060000\n",
      "Written lines ... 2070000\n",
      "Written lines ... 2080000\n",
      "Written lines ... 2090000\n",
      "Written lines ... 2100000\n",
      "Written lines ... 2110000\n",
      "Written lines ... 2120000\n",
      "Written lines ... 2130000\n",
      "Written lines ... 2140000\n",
      "Written lines ... 2150000\n",
      "Written lines ... 2160000\n",
      "Written lines ... 2170000\n",
      "Written lines ... 2180000\n",
      "Written lines ... 2190000\n",
      "Written lines ... 2200000\n",
      "Written lines ... 2210000\n",
      "Written lines ... 2220000\n",
      "Written lines ... 2230000\n",
      "Written lines ... 2240000\n",
      "Written lines ... 2250000\n",
      "Written lines ... 2260000\n",
      "Written lines ... 2270000\n",
      "Written lines ... 2280000\n",
      "Written lines ... 2290000\n",
      "Written lines ... 2300000\n",
      "Written lines ... 2310000\n",
      "Written lines ... 2320000\n",
      "Written lines ... 2330000\n",
      "Written lines ... 2340000\n",
      "Written lines ... 2350000\n",
      "Written lines ... 2360000\n",
      "Written lines ... 2370000\n",
      "Written lines ... 2380000\n",
      "Written lines ... 2390000\n",
      "Written lines ... 2400000\n",
      "Written lines ... 2410000\n",
      "Written lines ... 2420000\n",
      "Written lines ... 2430000\n",
      "Written lines ... 2440000\n",
      "Written lines ... 2450000\n",
      "Written lines ... 2460000\n",
      "Written lines ... 2470000\n",
      "Written lines ... 2480000\n",
      "Written lines ... 2490000\n",
      "Written lines ... 2500000\n",
      "Written lines ... 2510000\n",
      "Written lines ... 2520000\n",
      "Written lines ... 2530000\n",
      "Written lines ... 2540000\n",
      "Written lines ... 2550000\n",
      "Written lines ... 2560000\n",
      "Written lines ... 2570000\n",
      "Written lines ... 2580000\n",
      "Written lines ... 2590000\n",
      "Written lines ... 2600000\n",
      "Written lines ... 2610000\n",
      "Written lines ... 2620000\n",
      "Written lines ... 2630000\n",
      "Written lines ... 2640000\n",
      "Written lines ... 2650000\n",
      "Written lines ... 2660000\n",
      "Written lines ... 2670000\n",
      "Written lines ... 2680000\n",
      "Written lines ... 2690000\n",
      "Written lines ... 2700000\n",
      "Written lines ... 2710000\n",
      "Written lines ... 2720000\n",
      "Written lines ... 2730000\n",
      "Written lines ... 2740000\n",
      "Written lines ... 2750000\n",
      "Written lines ... 2760000\n",
      "Written lines ... 2770000\n",
      "Written lines ... 2780000\n",
      "Written lines ... 2790000\n",
      "Written lines ... 2800000\n",
      "Written lines ... 2810000\n",
      "Written lines ... 2820000\n",
      "Written lines ... 2830000\n",
      "Written lines ... 2840000\n",
      "Written lines ... 2850000\n",
      "Written lines ... 2860000\n",
      "Written lines ... 2870000\n",
      "Written lines ... 2880000\n",
      "Written lines ... 2890000\n",
      "Written lines ... 2900000\n",
      "Written lines ... 2910000\n",
      "Written lines ... 2920000\n",
      "Written lines ... 2930000\n",
      "Written lines ... 2940000\n",
      "Written lines ... 2950000\n",
      "Written lines ... 2960000\n",
      "Written lines ... 2970000\n",
      "Written lines ... 2980000\n",
      "Written lines ... 2990000\n",
      "Written lines ... 3000000\n",
      "Written lines ... 3010000\n",
      "Written lines ... 3020000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written lines ... 3030000\n",
      "Written lines ... 3040000\n",
      "Written lines ... 3050000\n",
      "Written lines ... 3060000\n",
      "Written lines ... 3070000\n",
      "Written lines ... 3080000\n",
      "Written lines ... 3090000\n",
      "Written lines ... 3100000\n",
      "Written lines ... 3110000\n",
      "Written lines ... 3120000\n",
      "Written lines ... 3130000\n",
      "Written lines ... 3140000\n",
      "Written lines ... 3150000\n",
      "Written lines ... 3160000\n",
      "Written lines ... 3170000\n",
      "Written lines ... 3180000\n",
      "Written lines ... 3190000\n",
      "Written lines ... 3200000\n",
      "Written lines ... 3210000\n",
      "Written lines ... 3220000\n",
      "Written lines ... 3230000\n",
      "Written lines ... 3240000\n",
      "Written lines ... 3250000\n",
      "Written lines ... 3260000\n",
      "Written lines ... 3270000\n",
      "Written lines ... 3280000\n",
      "Written lines ... 3290000\n",
      "Written lines ... 3300000\n",
      "Written lines ... 3310000\n",
      "Written lines ... 3320000\n",
      "Written lines ... 3330000\n",
      "Written lines ... 3340000\n",
      "Written lines ... 3350000\n",
      "Written lines ... 3360000\n",
      "Written lines ... 3370000\n",
      "Skipped 0 elements with sequence length != 200\n",
      "Converting and storing sequences of length 200 bp.\n",
      "Written lines ... 0\n",
      "Written lines ... 10000\n",
      "Written lines ... 20000\n",
      "Written lines ... 30000\n",
      "Written lines ... 40000\n",
      "Written lines ... 50000\n",
      "Written lines ... 60000\n",
      "Written lines ... 70000\n",
      "Written lines ... 80000\n",
      "Written lines ... 90000\n",
      "Written lines ... 100000\n",
      "Written lines ... 110000\n",
      "Written lines ... 120000\n",
      "Written lines ... 130000\n",
      "Written lines ... 140000\n",
      "Written lines ... 150000\n",
      "Written lines ... 160000\n",
      "Written lines ... 170000\n",
      "Written lines ... 180000\n",
      "Written lines ... 190000\n",
      "Skipped 0 elements with sequence length != 200\n",
      "\n",
      "Saved the data Data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python preprocess/generate_h5.py --data_prefix data/single_cell_type/{cell_type}_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model\n",
    "* Train from the .h5 train datasete for 15 epochs with deephaem pretrained model\n",
    "* Test from the .h5 test dataset\n",
    "* If gpu devices available, `CUDA_VISIBLE_DEVICES` with known number can be assigned to accelerate the training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From accuEnhancer.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Start to read from h5 files to Numpy array:\n",
      "Finished reading training....\n",
      "\n",
      "\n",
      "training_data\n",
      "(3378503, 200, 4)\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "2020-10-16 02:52:55.793485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-16 02:52:55.835254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:55.835620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 02:52:55.835657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:55.835996: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 02:52:55.836113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 02:52:55.836845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 02:52:55.837468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 02:52:55.837630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 02:52:55.838478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 02:52:55.839128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 02:52:55.841049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 02:52:55.841135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:55.841530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:55.841891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:55.842249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:55.842584: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 02:52:55.842787: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-10-16 02:52:55.865334: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2020-10-16 02:52:55.865769: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557785c156f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 02:52:55.865782: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-16 02:52:56.185442: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.185878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 02:52:56.185930: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.186342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 02:52:56.186368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 02:52:56.186378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 02:52:56.186389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 02:52:56.186399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 02:52:56.186408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 02:52:56.186417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 02:52:56.186426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 02:52:56.186467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.186907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.187345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.187781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.188188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 02:52:56.188212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 02:52:56.189344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-16 02:52:56.189357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-10-16 02:52:56.189362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-10-16 02:52:56.189365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-10-16 02:52:56.189448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.189896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.190339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.190782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.191210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10287 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2020-10-16 02:52:56.191473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.191921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 02:52:56.192340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10311 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2020-10-16 02:52:56.193612: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x557788fe57f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 02:52:56.193625: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2020-10-16 02:52:56.193630: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train from the beginning!\n",
      "---- Training 0 iteration------------\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "2020-10-16 02:53:05.717351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 02:53:06.285130: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "3209577/3209577 [==============================] - 216s 67us/step - loss: 0.1732 - accuracy_m: 0.9580 - recall_m: 0.8453 - precision_m: 0.7428 - f1_m: 0.7895 - recall_keras: 0.8453 - precision_keras: 0.7428 - f1_keras: 0.7895 - val_loss: 0.0477 - val_accuracy_m: 0.9816 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 209s 65us/step - loss: 0.1424 - accuracy_m: 0.9614 - recall_m: 0.8476 - precision_m: 0.7578 - f1_m: 0.7998 - recall_keras: 0.8476 - precision_keras: 0.7578 - f1_keras: 0.7998 - val_loss: 0.0471 - val_accuracy_m: 0.9817 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_0.h5\n",
      "---- Training 1 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      " 156000/3209577 [>.............................] - ETA: 3:12 - loss: 0.1375 - accuracy_m: 0.9627 - recall_m: 0.8517 - precision_m: 0.7627 - f1_m: 0.8044 - recall_keras: 0.8517 - precision_keras: 0.7627 - f1_keras: 0.8044^C\n",
      "Traceback (most recent call last):\n",
      "  File \"accuEnhancer.py\", line 282, in <module>\n",
      "    model.fit([dna_train, epi_train], y_train, epochs=2, batch_size=4000, class_weight={0: 1, 1: 2}, validation_split=0.05)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/engine/training.py\", line 1239, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 196, in fit_loop\n",
      "    outs = fit_function(ins_batch)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! CUDA_VISIBLE_DEVICES=0,1 python accuEnhancer.py \\\n",
    "    --in_file data/single_cell_type/{cell_type}_out_dnase_dataset.h5 \\\n",
    "    --out_name data/{cell_type} \\\n",
    "    --epoch 15 \\\n",
    "    --deephaem_model_path models/deephaem_erythroid_saved_conv_weights.npz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If the training was interrupted, load the checkpoint from last epcoh: from checkpoint 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From accuEnhancer.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Start to read from h5 files to Numpy array:\n",
      "Finished reading training....\n",
      "\n",
      "\n",
      "training_data\n",
      "(3378503, 200, 4)\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "2020-10-16 04:05:00.849849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-16 04:05:00.892260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:00.892696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 04:05:00.892739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:00.893150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 04:05:00.893284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 04:05:00.894170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 04:05:00.894848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 04:05:00.895017: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 04:05:00.895989: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 04:05:00.896705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 04:05:00.898882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 04:05:00.898935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:00.899346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:00.899719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:00.900087: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:00.900433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 04:05:00.900643: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-10-16 04:05:00.921339: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2020-10-16 04:05:00.921631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5578160eb760 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 04:05:00.921641: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-16 04:05:01.229793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.230232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 04:05:01.230285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.230696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 04:05:01.230721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 04:05:01.230731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 04:05:01.230741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 04:05:01.230751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 04:05:01.230761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 04:05:01.230771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 04:05:01.230781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 04:05:01.230821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.231259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.231696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.232133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.232541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 04:05:01.232565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 04:05:01.233709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-16 04:05:01.233721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-10-16 04:05:01.233726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-10-16 04:05:01.233729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-10-16 04:05:01.233820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.234268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.234712: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.235155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.235578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10287 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2020-10-16 04:05:01.235837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.236286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 04:05:01.236705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10311 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2020-10-16 04:05:01.237959: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5578196dd030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 04:05:01.237972: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2020-10-16 04:05:01.237977: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0 weights are loaded.\n",
      "---- Training 1 iteration------------\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "2020-10-16 04:05:11.323141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 04:05:11.913860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "3209577/3209577 [==============================] - 216s 67us/step - loss: 0.1434 - accuracy_m: 0.9610 - recall_m: 0.8468 - precision_m: 0.7557 - f1_m: 0.7982 - recall_keras: 0.8468 - precision_keras: 0.7557 - f1_keras: 0.7982 - val_loss: 0.0710 - val_accuracy_m: 0.9710 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 209s 65us/step - loss: 0.1401 - accuracy_m: 0.9619 - recall_m: 0.8507 - precision_m: 0.7596 - f1_m: 0.8022 - recall_keras: 0.8507 - precision_keras: 0.7596 - f1_keras: 0.8022 - val_loss: 0.0884 - val_accuracy_m: 0.9665 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_1.h5\n",
      "---- Training 2 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 214s 67us/step - loss: 0.1349 - accuracy_m: 0.9626 - recall_m: 0.8570 - precision_m: 0.7624 - f1_m: 0.8066 - recall_keras: 0.8570 - precision_keras: 0.7624 - f1_keras: 0.8066 - val_loss: 0.0663 - val_accuracy_m: 0.9725 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 216s 67us/step - loss: 0.1176 - accuracy_m: 0.9648 - recall_m: 0.8797 - precision_m: 0.7682 - f1_m: 0.8198 - recall_keras: 0.8797 - precision_keras: 0.7682 - f1_keras: 0.8198 - val_loss: 0.0915 - val_accuracy_m: 0.9608 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_2.h5\n",
      "---- Training 3 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 217s 68us/step - loss: 0.0832 - accuracy_m: 0.9729 - recall_m: 0.9338 - precision_m: 0.8020 - f1_m: 0.8626 - recall_keras: 0.9338 - precision_keras: 0.8020 - f1_keras: 0.8626 - val_loss: 0.0393 - val_accuracy_m: 0.9816 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 219s 68us/step - loss: 0.0589 - accuracy_m: 0.9813 - recall_m: 0.9606 - precision_m: 0.8532 - f1_m: 0.9035 - recall_keras: 0.9606 - precision_keras: 0.8532 - f1_keras: 0.9035 - val_loss: 0.1088 - val_accuracy_m: 0.9550 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_3.h5\n",
      "---- Training 4 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 219s 68us/step - loss: 0.0413 - accuracy_m: 0.9874 - recall_m: 0.9734 - precision_m: 0.8972 - f1_m: 0.9335 - recall_keras: 0.9734 - precision_keras: 0.8972 - f1_keras: 0.9335 - val_loss: 0.1052 - val_accuracy_m: 0.9656 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 220s 69us/step - loss: 0.0294 - accuracy_m: 0.9913 - recall_m: 0.9790 - precision_m: 0.9294 - f1_m: 0.9534 - recall_keras: 0.9790 - precision_keras: 0.9294 - f1_keras: 0.9534 - val_loss: 0.0892 - val_accuracy_m: 0.9733 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_4.h5\n",
      "---- Training 5 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 220s 68us/step - loss: 0.0209 - accuracy_m: 0.9940 - recall_m: 0.9833 - precision_m: 0.9523 - f1_m: 0.9675 - recall_keras: 0.9833 - precision_keras: 0.9523 - f1_keras: 0.9675 - val_loss: 0.0957 - val_accuracy_m: 0.9734 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 222s 69us/step - loss: 0.0153 - accuracy_m: 0.9957 - recall_m: 0.9866 - precision_m: 0.9669 - f1_m: 0.9766 - recall_keras: 0.9866 - precision_keras: 0.9669 - f1_keras: 0.9766 - val_loss: 0.1285 - val_accuracy_m: 0.9716 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_5.h5\n",
      "---- Training 6 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 221s 69us/step - loss: 0.0130 - accuracy_m: 0.9964 - recall_m: 0.9880 - precision_m: 0.9724 - f1_m: 0.9801 - recall_keras: 0.9880 - precision_keras: 0.9724 - f1_keras: 0.9801 - val_loss: 0.0861 - val_accuracy_m: 0.9806 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 222s 69us/step - loss: 0.0112 - accuracy_m: 0.9968 - recall_m: 0.9893 - precision_m: 0.9761 - f1_m: 0.9826 - recall_keras: 0.9893 - precision_keras: 0.9761 - f1_keras: 0.9826 - val_loss: 0.1211 - val_accuracy_m: 0.9734 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_6.h5\n",
      "---- Training 7 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 221s 69us/step - loss: 0.0101 - accuracy_m: 0.9972 - recall_m: 0.9905 - precision_m: 0.9789 - f1_m: 0.9846 - recall_keras: 0.9905 - precision_keras: 0.9789 - f1_keras: 0.9846 - val_loss: 0.1253 - val_accuracy_m: 0.9754 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 221s 69us/step - loss: 0.0093 - accuracy_m: 0.9974 - recall_m: 0.9911 - precision_m: 0.9807 - f1_m: 0.9858 - recall_keras: 0.9911 - precision_keras: 0.9807 - f1_keras: 0.9858 - val_loss: 0.0895 - val_accuracy_m: 0.9796 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_7.h5\n",
      "---- Training 8 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 221s 69us/step - loss: 0.0089 - accuracy_m: 0.9976 - recall_m: 0.9915 - precision_m: 0.9818 - f1_m: 0.9866 - recall_keras: 0.9915 - precision_keras: 0.9818 - f1_keras: 0.9866 - val_loss: 0.0812 - val_accuracy_m: 0.9826 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 222s 69us/step - loss: 0.0084 - accuracy_m: 0.9977 - recall_m: 0.9921 - precision_m: 0.9825 - f1_m: 0.9872 - recall_keras: 0.9921 - precision_keras: 0.9825 - f1_keras: 0.9872 - val_loss: 0.1643 - val_accuracy_m: 0.9684 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_8.h5\n",
      "---- Training 9 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 221s 69us/step - loss: 0.0079 - accuracy_m: 0.9978 - recall_m: 0.9924 - precision_m: 0.9837 - f1_m: 0.9880 - recall_keras: 0.9924 - precision_keras: 0.9837 - f1_keras: 0.9880 - val_loss: 0.1650 - val_accuracy_m: 0.9693 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 223s 69us/step - loss: 0.0074 - accuracy_m: 0.9980 - recall_m: 0.9928 - precision_m: 0.9850 - f1_m: 0.9889 - recall_keras: 0.9928 - precision_keras: 0.9850 - f1_keras: 0.9889 - val_loss: 0.0854 - val_accuracy_m: 0.9832 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_9.h5\n",
      "---- Training 10 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "^C 4000/3209577 [..............................] - ETA: 4:21 - loss: 0.0041 - accuracy_m: 0.9992 - recall_m: 1.0000 - precision_m: 0.9916 - f1_m: 0.9958 - recall_keras: 1.0000 - precision_keras: 0.9916 - f1_keras: 0.99\n",
      "Traceback (most recent call last):\n",
      "  File \"accuEnhancer.py\", line 271, in <module>\n",
      "    model.fit([dna_train, epi_train], y_train, epochs=2, batch_size=4000, class_weight={0: 1, 1: 2}, validation_split=0.05)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/engine/training.py\", line 1239, in fit\n",
      "    validation_freq=validation_freq)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/engine/training_arrays.py\", line 196, in fit_loop\n",
      "    outs = fit_function(ins_batch)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
      "    run_metadata=self.run_metadata)\n",
      "  File \"/tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "! CUDA_VISIBLE_DEVICES=0,1 python accuEnhancer.py \\\n",
    "    --in_file data/single_cell_type/{cell_type}_out_dnase_dataset.h5 \\\n",
    "    --out_name data/{cell_type} \\\n",
    "    --epoch 15 \\\n",
    "    --train_from_ckpt 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### from checkpoint 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From accuEnhancer.py:16: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Start to read from h5 files to Numpy array:\n",
      "Finished reading training....\n",
      "\n",
      "\n",
      "training_data\n",
      "(3378503, 200, 4)\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "2020-10-16 15:55:10.715264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-16 15:55:10.749709: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:10.750108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 15:55:10.750146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:10.750530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 15:55:10.750680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 15:55:10.751473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 15:55:10.752114: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 15:55:10.752297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 15:55:10.753198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 15:55:10.753804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 15:55:10.755693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 15:55:10.755739: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:10.756110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:10.756471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:10.756828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:10.757212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 15:55:10.757416: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-10-16 15:55:10.777374: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2020-10-16 15:55:10.778244: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56071b9e2f70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 15:55:10.778281: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-16 15:55:11.089670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.090107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 15:55:11.090159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.090572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 15:55:11.090598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 15:55:11.090608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 15:55:11.090617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 15:55:11.090627: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 15:55:11.090638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 15:55:11.090647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 15:55:11.090656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 15:55:11.090694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.091133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.091571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.092007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.092414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 15:55:11.092441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 15:55:11.093568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-16 15:55:11.093580: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-10-16 15:55:11.093585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-10-16 15:55:11.093589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-10-16 15:55:11.093676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.094124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.094567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.095009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.095436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10287 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2020-10-16 15:55:11.095649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.096098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 15:55:11.096516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10311 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2020-10-16 15:55:11.097776: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56071efd41d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 15:55:11.097789: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2020-10-16 15:55:11.097795: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 9 weights are loaded.\n",
      "---- Training 10 iteration------------\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "2020-10-16 15:55:21.266634: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 15:55:21.830169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "3209577/3209577 [==============================] - 216s 67us/step - loss: 0.1475 - accuracy_m: 0.9609 - recall_m: 0.8423 - precision_m: 0.7566 - f1_m: 0.7967 - recall_keras: 0.8423 - precision_keras: 0.7566 - f1_keras: 0.7967 - val_loss: 0.0517 - val_accuracy_m: 0.9788 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 210s 65us/step - loss: 0.1378 - accuracy_m: 0.9624 - recall_m: 0.8522 - precision_m: 0.7630 - f1_m: 0.8048 - recall_keras: 0.8522 - precision_keras: 0.7630 - f1_keras: 0.8048 - val_loss: 0.0428 - val_accuracy_m: 0.9815 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_10.h5\n",
      "---- Training 11 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 216s 67us/step - loss: 0.1190 - accuracy_m: 0.9657 - recall_m: 0.8747 - precision_m: 0.7771 - f1_m: 0.8227 - recall_keras: 0.8747 - precision_keras: 0.7771 - f1_keras: 0.8227 - val_loss: 0.0716 - val_accuracy_m: 0.9709 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 219s 68us/step - loss: 0.0679 - accuracy_m: 0.9785 - recall_m: 0.9468 - precision_m: 0.8385 - f1_m: 0.8891 - recall_keras: 0.9468 - precision_keras: 0.8385 - f1_keras: 0.8891 - val_loss: 0.0446 - val_accuracy_m: 0.9812 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_11.h5\n",
      "---- Training 12 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 221s 69us/step - loss: 0.0372 - accuracy_m: 0.9890 - recall_m: 0.9721 - precision_m: 0.9127 - f1_m: 0.9413 - recall_keras: 0.9721 - precision_keras: 0.9127 - f1_keras: 0.9413 - val_loss: 0.1026 - val_accuracy_m: 0.9687 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 223s 70us/step - loss: 0.0214 - accuracy_m: 0.9940 - recall_m: 0.9819 - precision_m: 0.9532 - f1_m: 0.9673 - recall_keras: 0.9819 - precision_keras: 0.9532 - f1_keras: 0.9673 - val_loss: 0.1079 - val_accuracy_m: 0.9706 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_12.h5\n",
      "---- Training 13 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 223s 69us/step - loss: 0.0148 - accuracy_m: 0.9959 - recall_m: 0.9863 - precision_m: 0.9689 - f1_m: 0.9775 - recall_keras: 0.9863 - precision_keras: 0.9689 - f1_keras: 0.9775 - val_loss: 0.1160 - val_accuracy_m: 0.9693 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 224s 70us/step - loss: 0.0120 - accuracy_m: 0.9966 - recall_m: 0.9886 - precision_m: 0.9748 - f1_m: 0.9816 - recall_keras: 0.9886 - precision_keras: 0.9748 - f1_keras: 0.9816 - val_loss: 0.1603 - val_accuracy_m: 0.9664 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_13.h5\n",
      "---- Training 14 iteration------------\n",
      "Train on 3209577 samples, validate on 168926 samples\n",
      "Epoch 1/2\n",
      "3209577/3209577 [==============================] - 223s 70us/step - loss: 0.0109 - accuracy_m: 0.9970 - recall_m: 0.9895 - precision_m: 0.9777 - f1_m: 0.9835 - recall_keras: 0.9895 - precision_keras: 0.9777 - f1_keras: 0.9835 - val_loss: 0.1387 - val_accuracy_m: 0.9701 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "Epoch 2/2\n",
      "3209577/3209577 [==============================] - 224s 70us/step - loss: 0.0098 - accuracy_m: 0.9973 - recall_m: 0.9904 - precision_m: 0.9799 - f1_m: 0.9851 - recall_keras: 0.9904 - precision_keras: 0.9799 - f1_keras: 0.9851 - val_loss: 0.1138 - val_accuracy_m: 0.9770 - val_recall_m: nan - val_precision_m: 0.0000e+00 - val_f1_m: nan - val_recall_keras: 0.0000e+00 - val_precision_keras: 0.0000e+00 - val_f1_keras: 0.0000e+00\n",
      "\n",
      "Save model to path: reports/data/E034/trained_14.h5\n",
      "\n",
      "---- Testing ------------\n",
      "\n",
      "Output checkpoint testing result------------\n",
      "test_data\n",
      "(194913, 200, 4)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "test loss: ----\n",
      "\n",
      "test accuracy:  0.9391523397618424\n",
      "\n",
      "test recall:  0.7478836386024319\n",
      "\n",
      "test precision:  0.8687645270874307\n",
      "\n",
      "test f1_score:  0.8038047973531844\n"
     ]
    }
   ],
   "source": [
    "! CUDA_VISIBLE_DEVICES=0,1 python accuEnhancer.py \\\n",
    "    --in_file data/single_cell_type/{cell_type}_out_dnase_dataset.h5 \\\n",
    "    --out_name data/{cell_type} \\\n",
    "    --epoch 15 \\\n",
    "    --train_from_ckpt 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independent prediction\n",
    "* Self-prepared 200-bp bed file (and/or fasta) as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t114377468\t114377668\r\n",
      "chr1\t713000\t713200\r\n"
     ]
    }
   ],
   "source": [
    "! cat data/test.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">chr1:114377468-114377668\r\n",
      "ttaaaggcatgagccaccatgcccATCCCACACTTTATTTTATACTTACTGAACTGTACTCACCAGCTTCCTCAACCACAATAAATGATTCAGGTGTCCATACAGGAAGTGGAGGGGGGATTTCATCATCTATCCTTGGAGCAGTTGCTATCCAAAATGTCAAAAATATTGTAACAATTGTTAATTAGAACAATCCAAAG\r\n",
      ">chr1:713000-713200\r\n",
      "ggctggggtgcagtggtgtgatcttggcccagtgcaacctctgcctcccgggttcaagtaattctcctttatcagcctcccaggtagctgggactacaggcatgcgccaccacggccagctaatttttgtattttttgtagagactgggtttcaccatggccaggctggtctccaactcctgacctcaggtgatccaccc\r\n"
     ]
    }
   ],
   "source": [
    "! bedtools getfasta -fi data/genome/hg19.fa -bed data/test.bed -fo data/test.fa.out\n",
    "! cat data/test.fa.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "* Get corresponding dnase feature and H3K27ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'E034'\n",
    "h3k27ac_file = f'data/peakfiles/{cell_type}-H3K27ac.narrowPeak.gz'\n",
    "epi_file = f'data/peakfiles/{cell_type}-DNase.macs2.narrowPeak.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generate test data in the format of `<chr> <start> <end> <comma separated IDs> <raw sequence> <epi mark>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Now fetching signal values from h3k27ac bed files...\n",
      "### Now fetching signal values from dnase bed files...\n",
      "### Now processing positive bins...\n"
     ]
    }
   ],
   "source": [
    "!python preprocess/process_narrowpeaks_test.py \\\n",
    "        --h3k27ac_file {h3k27ac_file} \\\n",
    "        --epi_file {epi_file} \\\n",
    "        --hg38_fasta_bins data/test.fa.out \\\n",
    "        --hg38_bed_bins data/test.bed \\\n",
    "        --output_name {cell_type}_test_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* check the generated test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t114377468\t114377668\t0\tttaaaggcatgagccaccatgcccATCCCACACTTTATTTTATACTTACTGAACTGTACTCACCAGCTTCCTCAACCACAATAAATGATTCAGGTGTCCATACAGGAAGTGGAGGGGGGATTTCATCATCTATCCTTGGAGCAGTTGCTATCCAAAATGTCAAAAATATTGTAACAATTGTTAATTAGAACAATCCAAAG\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t12.91072\t12.91072\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\r\n",
      "chr1\t713000\t713200\t1\tggctggggtgcagtggtgtgatcttggcccagtgcaacctctgcctcccgggttcaagtaattctcctttatcagcctcccaggtagctgggactacaggcatgcgccaccacggccagctaatttttgtattttttgtagagactgggtttcaccatggccaggctggtctccaactcctgacctcaggtgatccaccc\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t0.0\t32.05043\t32.05043\t32.05043\t0.0\t6.65678\t0.0\t0.0\t0.0\t0.0\r\n"
     ]
    }
   ],
   "source": [
    "! cat data/single_cell_type/{cell_type}_test_out_dnase.test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pack to .h5 file for model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "# === Creating a Training, Test and Validation Set from provided input === #\r\n",
      "\r\n",
      "Reading lines ...\r\n",
      "\r\n",
      "Converting to binary representation:\r\n",
      "\r\n",
      "Sampled into sets ...\r\n",
      "\r\n",
      "Storing Coordinates ...\r\n",
      "\r\n",
      "Initializing hdf5 Storage Files ...\r\n",
      "\r\n",
      "Running through raw file again, converting sequences and store in sets ...\r\n",
      "Converting and storing sequences of length 200 bp.\r\n",
      "Written lines ... 0\r\n",
      "Skipped 0 elements with sequence length != 200\r\n",
      "\r\n",
      "Saved the data Data.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python preprocess/generate_h5_test.py --data_prefix data/single_cell_type/{cell_type}_test_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "* Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:tensorflow:From predict_test.py:17: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "Start to read from h5 files to Numpy array:\n",
      "test_data\n",
      "(2, 200, 4)\n",
      "\n",
      "\n",
      "\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "2020-10-16 17:20:00.442141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-16 17:20:00.483810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.484176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 17:20:00.484211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.484550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 17:20:00.484669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 17:20:00.485508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 17:20:00.486143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 17:20:00.486292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 17:20:00.487145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 17:20:00.487812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 17:20:00.489886: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 17:20:00.489936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.490311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.490673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.491029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.491364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 17:20:00.491607: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-10-16 17:20:00.513359: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\n",
      "2020-10-16 17:20:00.514167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb2554f3a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 17:20:00.514199: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-16 17:20:00.833620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.833950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:01:00.0\n",
      "2020-10-16 17:20:00.833989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.834297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:02:00.0\n",
      "2020-10-16 17:20:00.834317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 17:20:00.834325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 17:20:00.834332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2020-10-16 17:20:00.834339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2020-10-16 17:20:00.834348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2020-10-16 17:20:00.834356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2020-10-16 17:20:00.834364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-16 17:20:00.834393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.834719: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.835044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.835369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.835672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\n",
      "2020-10-16 17:20:00.835690: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2020-10-16 17:20:00.836524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-16 17:20:00.836533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 \n",
      "2020-10-16 17:20:00.836537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y \n",
      "2020-10-16 17:20:00.836539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N \n",
      "2020-10-16 17:20:00.836607: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.836941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.837326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.837655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.837972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10287 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)\n",
      "2020-10-16 17:20:00.838187: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.838543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-16 17:20:00.838854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10311 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:02:00.0, compute capability: 7.5)\n",
      "2020-10-16 17:20:00.839946: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb26fd7920 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-16 17:20:00.839955: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5\n",
      "2020-10-16 17:20:00.839959: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tf/bin/miniconda3/envs/tf1/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "2020-10-16 17:20:02.707880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2020-10-16 17:20:03.214577: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "Predict probability: [[0.00116857]\n",
      " [0.99360955]]\n",
      "\n",
      "test loss: ----\n",
      "\n",
      "test accuracy:  1.0\n",
      "\n",
      "test recall:  1.0\n",
      "\n",
      "test precision:  1.0\n",
      "\n",
      "test f1_score:  1.0\n"
     ]
    }
   ],
   "source": [
    "!python predict_test.py --in_file data/single_cell_type/{cell_type}_test_out_dnase_dataset.h5 --out_name data/{cell_type}_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
